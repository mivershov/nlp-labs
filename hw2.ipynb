{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2 по обработке текстов\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предварительная обработка данных\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "# отключим предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 2 columns):\n",
      "name       5001 non-null object\n",
      "is_male    5001 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "female = pd.read_csv('female.txt', sep='\\n', names=['name'])\n",
    "female['is_male'] = 0\n",
    "female.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2943 entries, 0 to 2942\n",
      "Data columns (total 2 columns):\n",
      "name       2943 non-null object\n",
      "is_male    2943 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 46.1+ KB\n"
     ]
    }
   ],
   "source": [
    "male = pd.read_csv('male.txt', sep='\\n', names=['name'])\n",
    "male['is_male'] = 1\n",
    "male.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2578, 2)\n",
      "(4636, 2)\n"
     ]
    }
   ],
   "source": [
    "#удаляю \"неоднозначные\" имена\n",
    "interception = female[female['name'].isin(male['name'])]['name']\n",
    "female = female[~female['name'].isin(interception)].reset_index()\n",
    "male = male[~male['name'].isin(interception)].reset_index()\n",
    "female.drop(['index'], inplace=True, axis=1)\n",
    "male.drop(['index'], inplace=True, axis=1)\n",
    "print(male.shape)\n",
    "print(female.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "(5000,)\n",
      "(2578,)\n",
      "(2578,)\n"
     ]
    }
   ],
   "source": [
    "#формирую train/test, чтобы в train было поровну имен каждого класса\n",
    "train = male.sample(2500, random_state=42).append(female.sample(2500, random_state=42))\n",
    "y_train = train['is_male']\n",
    "train.drop('is_male', inplace=True, axis=1)\n",
    "train = pd.Series(train.name)\n",
    "\n",
    "test = male.loc[~male.name.isin(train)].append(female.loc[female.name.isin(train)])\n",
    "y_test = test['is_male']\n",
    "test.drop('is_male', inplace=True, axis=1)\n",
    "test = pd.Series(test.name)\n",
    "\n",
    "print(train.shape)\n",
    "print(y_train.shape)\n",
    "print(test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808        Gaston\n",
       "1193        Jonah\n",
       "761     Frederich\n",
       "318         Bryan\n",
       "2470      Willard\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 2. Базовый метод классификации\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?\n",
    "\n",
    "Для генерации $n$-грамм используйте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.util import ngrams\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pattern = re.compile(r'\\s+')\n",
    "count_vect = CountVectorizer(analyzer=lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_ngrams(text, n=4):\n",
    "    text = pattern.sub(\"\", text).lower()\n",
    "    return list(ngrams(text, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6394)\n",
      "(2578, 6394)\n"
     ]
    }
   ],
   "source": [
    "train_n_grams = [build_ngrams(name) for name in train]\n",
    "test_n_grams = [build_ngrams(name) for name in test]\n",
    "\n",
    "X_train = count_vect.fit_transform(train_n_grams)\n",
    "X_test = count_vect.transform(test_n_grams)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При n=4 для n_gram метрики accuracy и F1 максимальны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.9531\n",
      "F1=0.4574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "acc = accuracy_score(predicted, y_test)\n",
    "f1 = f1_score(predicted, y_test, average = 'binary')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('F1={0:1.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEICAYAAACpqsStAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFGhJREFUeJzt3XvYVXWd9/H3F8g4+agIeIBE8cSYo2bJFBrhIQ/jiJam\nPVAeQmnyVPlYXR4yG516KqfMqWzUpswM0WcmPJEyOVqaqGiiSIBipMlJQFEQD4Df54+9YW7pPuwb\n3Gx+7vfruvbFvdf67bU+G5efe92/tfZNZCaSpDJ1aXQASdL6s8QlqWCWuCQVzBKXpIJZ4pJUMEtc\nkgpmiWuTEhE9IuLWiHgpIm7agO2MjohJb2e2RomID0fErEbn0KYpvE9c6yMiRgHnAEOAZcBU4J8z\n874N3O6ngbOAYZm5aoODbuIiIoFdM3N2o7OoTJ6Jq9Mi4hzgcuAbwDbADsCPgKPfhs0PAp5shgKv\nRUR0a3QGbeIy04ePmh/AFsBy4BPtjHk3lZKfV31cDry7um4E8Bzwf4DngfnAKdV1XwfeAFZW9zEG\nuBj4RYtt7wgk0K36/GTgT1R+GpgDjG6x/L4WrxsGTAFeqv45rMW6e4BLgN9XtzMJ6NvGe1uT/8st\n8h8D/D3wJPACcH6L8UOBycDS6tgfAJtV1/2u+l5eqb7fE1ps/yvAAuC6Ncuqr9m5uo99q8+3BxYD\nIxp9bPhozMMzcXXWh4DuwK/aGXMB8EFgH2BvKkV2YYv121L5ZjCASlH/MCK2ysyvUTm7H5+ZvTPz\nJ+0FiYhewBXAEZm5OZWintrKuD7A7dWxWwPfBW6PiK1bDBsFnAL0BzYDzm1n19tS+TsYAFwEXA18\nCng/8GHgoogYXB27Gvgi0JfK393BwOkAmTm8Ombv6vsd32L7faj8VDK25Y4z82kqBX99RPQEfgr8\nLDPvaSev3sEscXXW1sDibH+6YzTwT5n5fGYuonKG/ekW61dW16/MzIlUzkJ3X888bwJ7RkSPzJyf\nmdNbGXMk8FRmXpeZqzJzHDATOKrFmJ9m5pOZ+SpwI5VvQG1ZSWX+fyVwA5WC/n5mLqvufzqwF0Bm\nPpKZD1T3+2fg34CP1PCevpaZr1fzvEVmXg08BTwIbEflm6aalCWuzloC9O1grnZ74JkWz5+pLlu7\njXW+CawAenc2SGa+QmUK4h+B+RFxe0QMqSHPmkwDWjxf0Ik8SzJzdfXrNSW7sMX6V9e8PiJ2i4jb\nImJBRLxM5SeNvu1sG2BRZr7WwZirgT2Bf83M1zsYq3cwS1ydNRl4jco8cFvmUZkKWGOH6rL18QrQ\ns8XzbVuuzMw7M/OjVM5IZ1Ipt47yrMk0dz0zdcaVVHLtmpn/CzgfiA5e0+4tYxHRm8p1hp8AF1en\ni9SkLHF1Sma+RGUe+IcRcUxE9IyId0XEERHx7eqwccCFEdEvIvpWx/9iPXc5FRgeETtExBbAeWtW\nRMQ2ETGyOjf+OpVpmdWtbGMisFtEjIqIbhFxArAHcNt6ZuqMzYGXgeXVnxI+t876hcDgv3pV+74P\nPJKZp1KZ6//xBqdUsSxxdVpmfpfKPeIXAouAvwBnAhOqQy4FHgYeB6YBf6guW599/RcwvrqtR3hr\n8XahcpfLPCp3bHyE6kXDdbaxBPiH6tglVO4s+YfMXLw+mTrpXCoXTZdR+Slh/DrrLwaujYilEXF8\nRxuLiKOBw6lMIUHlv8O+ETH6bUusovhhH0kqmGfiklQwS1ySCmaJS1LBLHFJKljdf7nOysV/8sqp\nNklb7XBwoyNIbVq+Yk5HnycAPBOXpKJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPEJalglrgkFcwS\nl6SCWeKSVDBLXJIKZolLUsEscUkqmCUuSQWzxCWpYJa4JBXMEpekglniklQwS1ySCmaJS1LBLHFJ\nKpglLkkFs8QlqWCWuCQVzBKXpIJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPEJalglrgkFcwSl6SC\nWeKSVDBLXJIKZolLUsEscUkqmCUuSQWzxCWpYJa4JBXMEpekglniklQwS1ySCmaJS1LBLHFJKpgl\nLkkFs8QlqWCWuCQVzBKXpIJZ4pJUMEu8weYvXMQpZ36Fo0aN5ejRn+W6Gye8Zf1Pf/n/2HP/I3hx\n6UsAZCbf+N6VHHH8Z/jYiZ/jj7Nm/8+2FjzPaV84n6NGjWXk6LHMnb9wo74XNZfTTz+Zh6bcwZSH\n7+T0M055y7qzP38ay1fMYeutt2pQuubRrdEBml23rl350lmnscfuu/DKKys4fszZDNvvfey80yDm\nL1zE5CmPst02/deOv3fyFJ59bh4Tx/+Ex6fP5JLLfsC4qy8H4LxLL2PsiZ9k2NB9WbHiVaJLNOpt\n6R1ujz124+RTPslHhh/DG2+sZMLNP+POO+7m6af/zIAB23HQQQfw7LNzGx2zKXgm3mD9+vZhj913\nAaBXr54MHvQeFi5aAsC3r/g3zjl9DNGii+++7wFGHn4wEcHee/4Ny5YtZ9HiF3h6zjOsXr2aYUP3\nBaBnzx706N59o78fNYfdd9+Fh6ZM5dVXX2P16tXcd99DHDXyMAC+9e2vcuGF/5fMbHDK5tBhiUfE\nbhFxV0Q8UX2+V0RcWP9ozWfu/IXMeOpp9nrv7tx97wP079eXIbsOfsuYhYuWsG3/vmufb9O/LwsX\nLebPf5nL5r178/nzLuG4k8/gsh9cw+rVqzf2W1CT+OMfZ7H//kPp02dLevTozqGHjWDgwO34+yMP\nYd68BTwxbUajIzaNWs7ErwbOA1YCZObjwCfbe0FEjI2IhyPi4Wt+Pm7DUzaBFSte5YsXXMpXzv4s\nXbt25aqf38CZp376r8a1dnYTEaxevZo/PPYE5555KjdccwXPzVvAhIm/2RjR1YRmzXqa7333x9xy\n23VMuPlanpg2g1WrVvGlL5/BpZd8r9HxmkotJd4zMx9aZ9mq9l6QmVdl5gcy8wOnnvi/1z9dk1i5\nahVfuOBSjjz0QD46Yn/+Mnc+c+ct4NiTTufQY09i4aLFfOIzZ7F4yQts278vC55fvPa1C59fTP++\nW7NNv74M2W1n3jNgO7p168pBwz/EjCdnt7NXacP8/NobOWDYURx26Am88OJSnn3mOXYcNJDJD05k\n+ox7GTBgW+67/1b6b9O3441pvdVyYXNxROwMJEBEHAfMr2uqJpKZXPTNyxk86D2c9MmPA7Dbzjvx\nu9tvWDvm0GNPYvxPrmCrLbdgxAEfZNx/3MoRh3yEx6fPpHfvXvTr24c+W23By8uW88KLS+mz1ZY8\n9MhjvHfIro16W2oC/fptzaJFSxg4cHuOHnk4Bx34cX70o5+tXT99xr0MP2AkS5a82LiQTaCWEj8D\nuAoYEhFzgTnAp+qaqok8+vh0br3jLnbdeUeOPekMAD7/2ZMYPmxoq+OHf2g/7p08hSOO/ww9unfn\nkvO/CEDXrl0594xTGfP58yBhj9134biRh2+096Hmc/0vr6RPny1ZuXIV53zxIpYufbnRkZpS1HoF\nOSJ6AV0yc1lndrBy8Z+8RK1N0lY7HNzoCFKblq+YU9M9wm2eiUfEOW0sByAzv7teySRJb5v2plM2\n32gpJEnrpc0Sz8yvb8wgkqTO6/DCZkR0B8YA7wXWfgQwMz9Tx1ySpBrUcp/4dcC2wGHAb4GBQKcu\nbkqS6qOWEt8lM78KvJKZ1wJHAn9b31iSpFrUUuIrq38ujYg9gS2AHeuWSJJUs1o+7HNVRGwFfBW4\nBegNXFTXVJKkmnRY4pl5TfXL3wKD2xsrSdq4ark7ZUvgRCpTKGvHZ+bZ9YslSapFLdMpE4EHgGnA\nm/WNI0nqjFpKvHtmtvoRfElSY9V0n3hEnBYR20VEnzWPuieTJHWoljPxN4DvABdQ/Z3i1T+9yClJ\nDVZLiZ9D5QM/izscKUnaqGqZTpkOrKh3EElS59VyJr4amBoRdwOvr1noLYaS1Hi1lPiE6kOStImp\n5ROb10ZED2CHzJy1ETJJkmrU4Zx4RBwFTAXuqD7fJyJuqXcwSVLHarmweTEwFFgKkJlTgZ3qmEmS\nVKNaSnxVZr60zjL/BXtJ2gTUcmHziYgYBXSNiF2Bs4H76xtLklSLNs/EI+K66pdPU/n3NV8HxgEv\nA1+ofzRJUkfaOxN/f0QMAk4ADgT+pcW6nsBr9QwmSepYeyX+Yyp3pAwGHm6xPPB3p0jSJqHN6ZTM\nvCIz/wb498wc3OKxU2Za4JK0Cejw7pTM/NzGCCJJ6rxabjGUJG2iLHFJKpglLkkFs8QlqWCWuCQV\nzBKXpIJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPEJalglrgkFcwSl6SCWeKSVDBLXJIKZolLUsEs\ncUkqmCUuSQWzxCWpYJa4JBUsMrOuO+i22YD67kBaT10iGh1BatMbrz9X0wHqmbgkFcwSl6SCWeKS\nVDBLXJIKZolLUsEscUkqmCUuSQWzxCWpYJa4JBXMEpekglniklQwS1ySCmaJS1LBLHFJKpglLkkF\ns8QlqWCWuCQVzBKXpIJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPEJalglrgkFcwSl6SCWeKSVDBL\nXJIKZolLUsEscUkqmCUuSQWzxCWpYJa4JBXMEpekglniklQwS1ySCmaJS1LBLHFJKpglLkkFs8Ql\nqWCWuCQVzBKXpIJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPEJalglrgkFcwS30QNHLg9v5l0E9Me\nv4fHpv43Z505BoBfXn8lD0+ZxMNTJjH7yQd4eMqkBidVs3py1mT+8MhvmPLQnUy+/3YAjv34kUx9\n9C5ee/VZ9t13rwYnbA7dGh1ArVu1ahVf+vLXeXTqE/Tu3YuHHryD39z1O0aN/tzaMd/51kW89PLL\nDUypZvfRQz/BkiUvrn0+/Y+zOP6E0/jhD77VwFTNxRLfRC1Y8DwLFjwPwPLlrzBz5lMM2H5bZsx4\nau2Y4447io8ednyjIkp/ZebM2Y2O0HRqnk6JiB4RsXs9w6h1gwYNZJ+99+TBhx5du+zDB/wdC59f\nxOzZcxqYTM0sSSbe/ksemDyRMWNGNzpO06rpTDwijgIuAzYDdoqIfYB/ysyRbYwfC4wFiK5b0KVL\nr7cpbvPp1asnN46/mnPO/RrLli1fu/yEE45h/PibG5hMzW7EiI8xf/5C+vXbml9PHMesWbO5774H\nGx2r6dR6Jn4xMBRYCpCZU4Ed2xqcmVdl5gcy8wMW+Prr1q0bN42/mnHjfsWECb9eu7xr16587Jgj\nuPGmWxqYTs1u/vyFACxatISbb76D/fbbp8GJmlOtJb4qM1+qaxL9lauv+hdmzJzN5d+/6i3LDzn4\nw8yaNZu5c+c3KJmaXc+ePejdu9farw85ZDjTp89qcKrmVGuJPxERo4CuEbFrRPwrcH8dczW9/Yft\nx6c/dRwHHjhs7S2FRxx+EADHH380NziVogbaZpt+3HP3r3h4yiTu//1t/PrXdzFp0j0cPfJw/vT0\nFD74wX25ecK13HbbLxod9R0vMrPjQRE9gQuAQ4EA7gQuyczXOnptt80GdLwDqQG6RDQ6gtSmN15/\nrqYDtKYS3xCWuDZVlrg2ZbWWeLt3p0TErUCbJdzW3SmSpI2jo1sML9soKSRJ66XdEs/M326sIJKk\nzqv1wz67At8E9gC6r1memYPrlEuSVINabzH8KXAlsAo4EPg5cF29QkmSalNriffIzLuo3M3yTGZe\nDBxUv1iSpFrU+lsMX4uILsBTEXEmMBfoX79YkqRa1Hom/gWgJ3A28H7gU8CJ9QolSapNrWfiSWUO\nfBDwruqyqwH/6Q5JaqBaS/x64EvANODN+sWRJHVGrSW+KDP9vaeStImptcS/FhHXAHcBr69ZmJn/\nWZdUkqSa1FripwBDqMyHr5lOScASl6QGqrXE987Mv61rEklSp9V6i+EDEbFHXZNIkjqt1jPxA4CT\nImIOlTnxADIzvcVQkhqo1hI/vK4pJEnrpaYSz8xn6h1EktR5tc6JS5I2QZa4JBXMEpekglniklQw\nS1ySCmaJS1LBLHFJKpglLkkFs8QlqWCWuCQVzBKXpIJZ4pJUMEtckgpmiUtSwSxxSSqYJS5JBbPE\nJalglrgkFcwSl6SCWeKSVDBLXJIKZolLUsEscUkqmCUuSQWzxCWpYJa4JBXMEpekglniklQwS1yS\nCmaJS1LBLHFJKlhkZqMzqBMiYmxmXtXoHNK6PDYbwzPx8oxtdACpDR6bDWCJS1LBLHFJKpglXh7n\nHLWp8thsAC9sSlLBPBOXpIJZ4pJUMEt8I4uIsyNiRkRcX6ftXxwR59Zj21JnRMSIiLit0Tne6bo1\nOkATOh04IjPnNDqIpPJ5Jr4RRcSPgcHALRFxQUT8e0RMiYhHI+Lo6piTI2JCRNwaEXMi4syIOKc6\n5oGI6FMdd1r1tY9FxH9ERM9W9rdzRNwREY9ExL0RMWTjvmOVLiJ2jIiZEXFNRDwREddHxCER8fuI\neCoihlYf91eP0fsjYvdWttOrteNdG84S34gy8x+BecCBQC/gvzNzv+rz70REr+rQPYFRwFDgn4EV\nmfk+YDJwYnXMf2bmfpm5NzADGNPKLq8CzsrM9wPnAj+qzzvTO9wuwPeBvYAhVI7NA6gcU+cDM4Hh\n1WP0IuAbrWzjAto+3rUBnE5pnEOBkS3mr7sDO1S/vjszlwHLIuIl4Nbq8mlU/kcC2DMiLgW2BHoD\nd7bceET0BoYBN0XEmsXvrscb0TvenMycBhAR04G7MjMjYhqwI7AFcG1E7Aok8K5WttHW8T6j3uHf\n6Szxxgng2Myc9ZaFEX8HvN5i0Zstnr/J//w3+xlwTGY+FhEnAyPW2X4XYGlm7vP2xlYT6uh4vITK\nicfHImJH4J5WttHq8a4N53RK49wJnBXV0+SIeF8nX785MD8i3gWMXndlZr4MzImIT1S3HxGx9wZm\nllqzBTC3+vXJbYzZ0ONdbbDEG+cSKj92Ph4RT1Sfd8ZXgQeB/6IyJ9ma0cCYiHgMmA54MUn18G3g\nmxHxe6BrG2M29HhXG/zYvSQVzDNxSSqYJS5JBbPEJalglrgkFcwSl6SCWeKSVDBLXJIK9v8BtEG0\nJxpd2aYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d36839c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классификатор в более половины случаев ошибается в определении мужских имен\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=['female', 'male'], yticklabels=['female', 'male'])\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()\n",
    "print(\"Классификатор в более половины случаев ошибается в определении мужских имен\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 3. Нейронная сеть\n",
    "\n",
    "\n",
    "Используйте  реккурентную нейронную сеть с  LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM).  У нейронной сети один выход, определяющий класс имени. \n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$.  \n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами. \n",
    "\n",
    "Сравните результаты классификации разными методами. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совсем не получается запрограммировать нейронную сеть самостоятельно, обратитесь к туториалу тут: https://github.com/divamgupta/lstm-gender-predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 55\n"
     ]
    }
   ],
   "source": [
    "chars = set(  \"\".join(female.name) + \"\".join(male.name)  )\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 5000\n",
      "max lengh: 15\n"
     ]
    }
   ],
   "source": [
    "totalEntriesTrain = len(train)\n",
    "maxlen = len(max( train , key=len))\n",
    "print('total entries:', totalEntriesTrain)\n",
    "print('max lengh:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries: 2578\n",
      "max lengh: 15\n"
     ]
    }
   ],
   "source": [
    "totalEntriesTest = len(test)\n",
    "maxlen = len(max( test , key=len))\n",
    "print('total entries:', totalEntriesTest)\n",
    "print('max lengh:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      female  male\n",
       "808        0     1\n",
       "1193       0     1\n",
       "761        0     1\n",
       "318        0     1\n",
       "2470       0     1\n",
       "2564       0     1\n",
       "812        0     1\n",
       "1684       0     1\n",
       "1089       0     1\n",
       "1565       0     1\n",
       "2393       0     1\n",
       "1053       0     1\n",
       "2576       0     1\n",
       "2459       0     1\n",
       "2113       0     1\n",
       "530        0     1\n",
       "289        0     1\n",
       "2174       0     1\n",
       "903        0     1\n",
       "1302       0     1\n",
       "354        0     1\n",
       "2575       0     1\n",
       "2034       0     1\n",
       "693        0     1\n",
       "1723       0     1\n",
       "834        0     1\n",
       "70         0     1\n",
       "56         0     1\n",
       "1598       0     1\n",
       "1289       0     1\n",
       "...      ...   ...\n",
       "1656       1     0\n",
       "2425       1     0\n",
       "3039       1     0\n",
       "3733       1     0\n",
       "4611       1     0\n",
       "2855       1     0\n",
       "4154       1     0\n",
       "4408       1     0\n",
       "3572       1     0\n",
       "1385       1     0\n",
       "3295       1     0\n",
       "1399       1     0\n",
       "1195       1     0\n",
       "1408       1     0\n",
       "3880       1     0\n",
       "1798       1     0\n",
       "1475       1     0\n",
       "4629       1     0\n",
       "35         1     0\n",
       "3053       1     0\n",
       "2345       1     0\n",
       "2742       1     0\n",
       "2359       1     0\n",
       "2206       1     0\n",
       "3240       1     0\n",
       "1286       1     0\n",
       "349        1     0\n",
       "3747       1     0\n",
       "2699       1     0\n",
       "1681       1     0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dum = pd.get_dummies(y_train)\n",
    "y_train_dum.columns = ['female', 'male']\n",
    "y_test_dum = pd.get_dummies(y_test)\n",
    "y_test_dum.columns = ['female', 'male']\n",
    "y_train_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((totalEntriesTrain , maxlen, len(chars) ), dtype=np.bool)\n",
    "y_train = np.zeros((totalEntriesTrain , 2 ), dtype=np.bool)\n",
    "X_test = np.zeros((totalEntriesTest , maxlen, len(chars) ), dtype=np.bool)\n",
    "y_test = np.zeros((totalEntriesTest , 2 ), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(train):\n",
    "    for t, char in enumerate(name):\n",
    "        X_train[i, t, char_indices[char]] = 1\n",
    "    y_train[i, 0] = y_train_dum['female'].iloc[i]\n",
    "    y_train[i, 1] = y_train_dum['male'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(test):\n",
    "    for t, char in enumerate(name):\n",
    "        X_test[i, t, char_indices[char]] = 1\n",
    "    y_test[i, 0] = y_test_dum['female'].iloc[i]\n",
    "    y_test[i, 1] = y_test_dum['male'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 15, 55)\n",
      "(5000, 2)\n",
      "(2578, 15, 55)\n",
      "(2578, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(tf.convert_to_tensor(y_true * y_pred, np.float32), 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(tf.convert_to_tensor(y_true, np.float32), 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(tf.convert_to_tensor(y_true * y_pred, np.float32), 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(tf.convert_to_tensor(y_pred, np.float32), 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "\n",
    "with open(\"model2.json\", \"w\") as text_file:\n",
    "    text_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 209s 42ms/step - loss: 0.5811 - acc: 0.7114 - f1: 0.7114\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 203s 41ms/step - loss: 0.5065 - acc: 0.7540 - f1: 0.7540\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 202s 40ms/step - loss: 0.4676 - acc: 0.7748 - f1: 0.7748\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 199s 40ms/step - loss: 0.4249 - acc: 0.8076 - f1: 0.8076\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 203s 41ms/step - loss: 0.4011 - acc: 0.8202 - f1: 0.8202\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 203s 41ms/step - loss: 0.3775 - acc: 0.8292 - f1: 0.8292\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 200s 40ms/step - loss: 0.3625 - acc: 0.8400 - f1: 0.8400\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 202s 40ms/step - loss: 0.3486 - acc: 0.8514 - f1: 0.8514\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 201s 40ms/step - loss: 0.3370 - acc: 0.8554 - f1: 0.8554\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 205s 41ms/step - loss: 0.3199 - acc: 0.8694 - f1: 0.8694\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 202s 40ms/step - loss: 0.3114 - acc: 0.8756 - f1: 0.8756\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 203s 41ms/step - loss: 0.2964 - acc: 0.8802 - f1: 0.8802\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 212s 42ms/step - loss: 0.2758 - acc: 0.8876 - f1: 0.8876\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 235s 47ms/step - loss: 0.2665 - acc: 0.8900 - f1: 0.8900\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 220s 44ms/step - loss: 0.2523 - acc: 0.9026 - f1: 0.9026\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 210s 42ms/step - loss: 0.2355 - acc: 0.9076 - f1: 0.9076\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 213s 43ms/step - loss: 0.2171 - acc: 0.9154 - f1: 0.9154\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 207s 41ms/step - loss: 0.2068 - acc: 0.9224 - f1: 0.9224\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 208s 42ms/step - loss: 0.1900 - acc: 0.9272 - f1: 0.9272\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 201s 40ms/step - loss: 0.1771 - acc: 0.9348 - f1: 0.9348\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 210s 42ms/step - loss: 0.1671 - acc: 0.9394 - f1: 0.9394\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 211s 42ms/step - loss: 0.1526 - acc: 0.9456 - f1: 0.9456\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 194s 39ms/step - loss: 0.1424 - acc: 0.9474 - f1: 0.9474\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 194s 39ms/step - loss: 0.1326 - acc: 0.9466 - f1: 0.9466\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 196s 39ms/step - loss: 0.1257 - acc: 0.9554 - f1: 0.9554\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 239s 48ms/step - loss: 0.1173 - acc: 0.9572 - f1: 0.9572\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 241s 48ms/step - loss: 0.1050 - acc: 0.9602 - f1: 0.9602\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 248s 50ms/step - loss: 0.0965 - acc: 0.9674 - f1: 0.9674\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 249s 50ms/step - loss: 0.0934 - acc: 0.9698 - f1: 0.9698\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 238s 48ms/step - loss: 0.0794 - acc: 0.9718 - f1: 0.9718\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 236s 47ms/step - loss: 0.0796 - acc: 0.9738 - f1: 0.9738\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 228s 46ms/step - loss: 0.0673 - acc: 0.9770 - f1: 0.9770\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 225s 45ms/step - loss: 0.0593 - acc: 0.9770 - f1: 0.9770\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 225s 45ms/step - loss: 0.0592 - acc: 0.9834 - f1: 0.9834\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 219s 44ms/step - loss: 0.0614 - acc: 0.9810 - f1: 0.9810\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 211s 42ms/step - loss: 0.0481 - acc: 0.9840 - f1: 0.9840\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 217s 43ms/step - loss: 0.0561 - acc: 0.9832 - f1: 0.9832\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 216s 43ms/step - loss: 0.0427 - acc: 0.9882 - f1: 0.9882\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 221s 44ms/step - loss: 0.0417 - acc: 0.9866 - f1: 0.9866\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 244s 49ms/step - loss: 0.0589 - acc: 0.9858 - f1: 0.9858\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 222s 44ms/step - loss: 0.0455 - acc: 0.9876 - f1: 0.9876\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 217s 43ms/step - loss: 0.0416 - acc: 0.9882 - f1: 0.9882\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 213s 43ms/step - loss: 0.0394 - acc: 0.9884 - f1: 0.9884\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 203s 41ms/step - loss: 0.0476 - acc: 0.9888 - f1: 0.9888\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 204s 41ms/step - loss: 0.0334 - acc: 0.9912 - f1: 0.9912\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 202s 40ms/step - loss: 0.0328 - acc: 0.9902 - f1: 0.9902\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 205s 41ms/step - loss: 0.0352 - acc: 0.9916 - f1: 0.9916\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 210s 42ms/step - loss: 0.0340 - acc: 0.9920 - f1: 0.9920\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 211s 42ms/step - loss: 0.0344 - acc: 0.9904 - f1: 0.9904\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 209s 42ms/step - loss: 0.0252 - acc: 0.9940 - f1: 0.9940\n",
      "Wall time: 2h 58min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d374e70080>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('my_model2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2578/2578 [==============================] - 32s 12ms/step\n",
      "score: [0.099121306166075521, 0.98138091543832429, 0.98138091543832429]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(\"score:\" , score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
